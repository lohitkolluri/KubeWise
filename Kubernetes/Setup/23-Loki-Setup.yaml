# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: loki-config
#   namespace: monitoring
# data:
#   loki.yaml: |
#     auth_enabled: false

#     server:
#       http_listen_port: 3100
#       log_level: info

#     limits_config:
#       enforce_metric_name: false
#       reject_old_samples: true
#       reject_old_samples_max_age: 168h
#       ingestion_rate_mb: 4
#       ingestion_burst_size_mb: 6

#     schema_config:
#       configs:
#         - from: 2020-10-24
#           store: boltdb-shipper
#           object_store: filesystem
#           schema: v11
#           index:
#             prefix: index_
#             period: 24h

#     storage_config:
#       boltdb_shipper:
#         active_index_directory: /data/loki/index
#         cache_location: /data/loki/cache
#         cache_ttl: 24h
#         shared_store: filesystem
#       filesystem:
#         directory: /data/loki/chunks

#     ruler:
#       alertmanager_url: http://alertmanager-service.monitoring.svc.cluster.local:9093
#       storage:
#         type: local
#         local:
#           directory: /rules
#       rule_path: /rules
#       ring:
#         kvstore:
#           store: inmemory
#       enable_api: true

#     ingester:
#       lifecycler:
#         address: 127.0.0.1
#         ring:
#           kvstore:
#             store: inmemory
#           replication_factor: 1
#         final_sleep: 0s
#       chunk_idle_period: 5m
#       chunk_retain_period: 30s

#   rules.yaml: |
#     groups:
#       - name: loki_alerts
#         rules:
#           # HTTP 500 error rate
#           - alert: HighErrorRate
#             expr: |
#               sum by (namespace, app) (
#                 rate({app=~".+"} |= "status=5.." [5m])
#               ) 
#               / 
#               sum by (namespace, app) (
#                 rate({app=~".+"} [5m])
#               ) > 0.05
#             for: 5m
#             labels:
#               severity: critical
#             annotations:
#               summary: "High error rate for {{ $labels.app }} in {{ $labels.namespace }}"
#               description: "Error rate is above 5% for the last 5 minutes"
#               remediation: "Check logs for detailed error information and restart service if needed"

#           # App crash or panic detection
#           - alert: ApplicationCrash
#             expr: |
#               sum by (namespace, app) (
#                 rate({app=~".+"} |~ "panic:|crash|fatal exception|segmentation fault" [10m])
#               ) > 0
#             for: 2m
#             labels:
#               severity: critical
#             annotations:
#               summary: "Application {{ $labels.app }} crash detected in {{ $labels.namespace }}"
#               description: "Application crash or panic detected in logs"
#               remediation: "Check logs for detailed crash information and restart service"

#           # Failed connection attempts
#           - alert: ConnectionFailures
#             expr: |
#               sum by (namespace, app) (
#                 rate({app=~".+"} |~ "connection refused|connection reset|connection failed|connection timeout" [10m])
#               ) > 5
#             for: 5m
#             labels:
#               severity: warning
#             annotations:
#               summary: "Connection failures detected for {{ $labels.app }} in {{ $labels.namespace }}"
#               description: "Multiple connection failures detected in logs"
#               remediation: "Check network connectivity and service dependencies"

#           # Authentication failures
#           - alert: AuthenticationFailures
#             expr: |
#               sum by (namespace, app) (
#                 rate({app=~".+"} |~ "authentication failed|auth.*failed|login failed|invalid credentials" [10m])
#               ) > 10
#             for: 5m
#             labels:
#               severity: warning
#             annotations:
#               summary: "High authentication failure rate for {{ $labels.app }} in {{ $labels.namespace }}"
#               description: "Multiple authentication failures detected in logs"
#               remediation: "Check for brute force attempts or credential issues"
# ---
# apiVersion: apps/v1
# kind: StatefulSet
# metadata:
#   name: loki
#   namespace: monitoring
#   labels:
#     app: loki
# spec:
#   serviceName: "loki"
#   replicas: 1
#   selector:
#     matchLabels:
#       app: loki
#   template:
#     metadata:
#       labels:
#         app: loki
#     spec:
#       securityContext:
#         fsGroup: 10001
#         runAsGroup: 10001
#         runAsNonRoot: true
#         runAsUser: 10001
#       containers:
#         - name: loki
#           image: grafana/loki:2.9.0
#           imagePullPolicy: Always
#           args:
#             - "-config.file=/etc/loki/loki.yaml"
#             - "-ruler.config=/etc/loki/rules/rules.yaml"
#           ports:
#             - name: http
#               containerPort: 3100
#               protocol: TCP
#           readinessProbe:
#             httpGet:
#               path: /ready
#               port: http
#             initialDelaySeconds: 45
#           livenessProbe:
#             httpGet:
#               path: /ready
#               port: http
#             initialDelaySeconds: 45
#           resources:
#             limits:
#               cpu: 200m
#               memory: 256Mi
#             requests:
#               cpu: 100m
#               memory: 128Mi
#           volumeMounts:
#             - name: loki-config
#               mountPath: /etc/loki
#             - name: loki-rules
#               mountPath: /etc/loki/rules
#             - name: loki-data
#               mountPath: /data
#       volumes:
#         - name: loki-config
#           configMap:
#             name: loki-config
#             items:
#               - key: loki.yaml
#                 path: loki.yaml
#         - name: loki-rules
#           configMap:
#             name: loki-config
#             items:
#               - key: rules.yaml
#                 path: rules.yaml
#   volumeClaimTemplates:
#     - metadata:
#         name: loki-data
#       spec:
#         accessModes: ["ReadWriteOnce"]
#         resources:
#           requests:
#             storage: 10Gi
# ---
# apiVersion: v1
# kind: Service
# metadata:
#   name: loki-service
#   namespace: monitoring
#   labels:
#     app: loki
# spec:
#   ports:
#     - port: 3100
#       protocol: TCP
#       name: http-metrics
#       targetPort: 3100
#   selector:
#     app: loki
# ---
# apiVersion: apps/v1
# kind: DaemonSet
# metadata:
#   name: promtail
#   namespace: monitoring
#   labels:
#     app: promtail
# spec:
#   selector:
#     matchLabels:
#       app: promtail
#   template:
#     metadata:
#       labels:
#         app: promtail
#     spec:
#       tolerations:
#       - operator: Exists
#       serviceAccountName: promtail
#       containers:
#       - name: promtail
#         image: grafana/promtail:2.9.0
#         args:
#         - -config.file=/etc/promtail/promtail.yaml
#         env:
#         - name: HOSTNAME
#           valueFrom:
#             fieldRef:
#               fieldPath: spec.nodeName
#         ports:
#         - containerPort: 9080
#           name: http-metrics
#         resources:
#           limits:
#             cpu: 200m
#             memory: 128Mi
#           requests:
#             cpu: 100m
#             memory: 64Mi
#         securityContext:
#           readOnlyRootFilesystem: true
#           runAsGroup: 0
#           runAsUser: 0
#         volumeMounts:
#         - name: config
#           mountPath: /etc/promtail
#         - name: containers
#           mountPath: /var/lib/docker/containers
#           readOnly: true
#         - name: pods
#           mountPath: /var/log/pods
#           readOnly: true
#       volumes:
#       - name: config
#         configMap:
#           name: promtail-config
#       - name: containers
#         hostPath:
#           path: /var/lib/docker/containers
#       - name: pods
#         hostPath:
#           path: /var/log/pods
# ---
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: promtail-config
#   namespace: monitoring
# data:
#   promtail.yaml: |
#     server:
#       http_listen_port: 9080
#       grpc_listen_port: 0

#     positions:
#       filename: /tmp/positions.yaml

#     clients:
#       - url: http://loki-service.monitoring.svc.cluster.local:3100/loki/api/v1/push

#     scrape_configs:
#     - job_name: kubernetes-pods
#       kubernetes_sd_configs:
#       - role: pod
#       relabel_configs:
#       - source_labels: [__meta_kubernetes_pod_node_name]
#         target_label: __host__
#       - action: labelmap
#         regex: __meta_kubernetes_pod_label_(.+)
#       - action: replace
#         replacement: $1
#         separator: /
#         source_labels:
#         - __meta_kubernetes_namespace
#         - __meta_kubernetes_pod_name
#         target_label: job
#       - action: replace
#         source_labels:
#         - __meta_kubernetes_namespace
#         target_label: namespace
#       - action: replace
#         source_labels:
#         - __meta_kubernetes_pod_name
#         target_label: pod
#       - action: replace
#         source_labels:
#         - __meta_kubernetes_pod_container_name
#         target_label: container
#       - replacement: /var/log/pods/*$1/*.log
#         separator: /
#         source_labels:
#         - __meta_kubernetes_pod_uid
#         - __meta_kubernetes_pod_container_name
#         target_label: __path__
# ---
# apiVersion: v1
# kind: ServiceAccount
# metadata:
#   name: promtail
#   namespace: monitoring
# ---
# apiVersion: rbac.authorization.k8s.io/v1
# kind: ClusterRole
# metadata:
#   name: promtail
# rules:
# - apiGroups: [""]
#   resources: ["nodes", "nodes/proxy", "pods"]
#   verbs: ["get", "list", "watch"]
# ---
# apiVersion: rbac.authorization.k8s.io/v1
# kind: ClusterRoleBinding
# metadata:
#   name: promtail
# roleRef:
#   apiGroup: rbac.authorization.k8s.io
#   kind: ClusterRole
#   name: promtail
# subjects:
# - kind: ServiceAccount
#   name: promtail
#   namespace: monitoring 