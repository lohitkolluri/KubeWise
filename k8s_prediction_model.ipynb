{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lohitkolluri/k8s-prediction-model/blob/main/k8s_prediction_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "J66FN-DuQ79Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 1: Install Required Libraries (if needed)\n",
        "\n",
        "!pip install tensorflow numpy pandas scikit-learn matplotlib imbalanced-learn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QCd5f0GJOFV",
        "outputId": "72387e56-6430-4ee0-b5a5-a43c12b6b20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 2: Generate Synthetic Kubernetes Data\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define simulation length (e.g., 1200 time steps ~ simulate 1200 minutes)\n",
        "N = 1200\n",
        "\n",
        "# Time index (representing minutes/seconds)\n",
        "time = np.arange(N)\n",
        "\n",
        "# Simulate normal Kubernetes cluster metrics\n",
        "cpu_usage = 50 + 10 * np.sin(2 * np.pi * time / 100) + np.random.normal(0, 3, N)\n",
        "mem_usage = 60 + 5 * np.sin(2 * np.pi * time / 150) + np.random.normal(0, 2, N)\n",
        "disk_usage = 70 + np.random.normal(0, 1, N)\n",
        "net_throughput = 100 + 20 * np.sin(2 * np.pi * time / 120) + np.random.normal(0, 5, N)\n",
        "active_nodes = np.full(N, 5)  # Assume 5 nodes normally\n",
        "active_pods = np.full(N, 50)  # Assume 50 pods normally\n",
        "error_rate = np.random.poisson(0.2, N)  # Few random errors\n",
        "\n",
        "# Clip values to realistic bounds\n",
        "cpu_usage = np.clip(cpu_usage, 0, 100)\n",
        "mem_usage = np.clip(mem_usage, 0, 100)\n",
        "disk_usage = np.clip(disk_usage, 0, 100)\n",
        "net_throughput = np.clip(net_throughput, 0, None)\n",
        "\n",
        "# Initialize anomaly labels (0 = Normal)\n",
        "labels = np.zeros(N, dtype=int)\n",
        "\n",
        "# Inject anomalies at specific time intervals\n",
        "anomalies = {\n",
        "    5: [(50, 59), (650, 659)],  # Node Failure\n",
        "    1: [(150, 159), (750, 759)],  # CPU Exhaustion\n",
        "    2: [(250, 259), (850, 859)],  # Memory Leak\n",
        "    3: [(350, 359), (950, 959)],  # Disk Saturation\n",
        "    4: [(450, 459), (1050, 1059)],  # Network Issue\n",
        "    6: [(550, 559), (1150, 1159)]  # Service Disruption\n",
        "}\n",
        "\n",
        "# Apply anomaly patterns to data\n",
        "for label, segments in anomalies.items():\n",
        "    for start, end in segments:\n",
        "        labels[start:end+1] = label\n",
        "        if label == 5:  # Node Failure\n",
        "            cpu_usage[start:end+1] *= 0.2\n",
        "            mem_usage[start:end+1] *= 0.2\n",
        "            net_throughput[start:end+1] *= 0.2\n",
        "            active_nodes[start:end+1] = 4\n",
        "            active_pods[start:end+1] -= 5\n",
        "        elif label == 1:  # CPU Exhaustion\n",
        "            cpu_usage[start:end+1] = 95 + np.random.normal(0, 2, end - start + 1)\n",
        "            cpu_usage[start:end+1] = np.clip(cpu_usage[start:end+1], 0, 100)\n",
        "        elif label == 2:  # Memory Leak\n",
        "            mem_trend = np.linspace(mem_usage[start-1], 98, end - start + 1)\n",
        "            mem_usage[start:end+1] = np.clip(mem_trend + np.random.normal(0, 1, end - start + 1), 0, 100)\n",
        "        elif label == 3:  # Disk Saturation\n",
        "            disk_usage[start:end+1] = np.clip(95 + np.random.normal(0, 1, end - start + 1), 0, 100)\n",
        "        elif label == 4:  # Network Issue\n",
        "            net_throughput[start:end+1] = np.clip(5 + np.random.normal(0, 1, end - start + 1), 0, None)\n",
        "        elif label == 6:  # Service Disruption\n",
        "            error_rate[start:end+1] = np.random.poisson(5, end - start + 1)\n",
        "            cpu_usage[start:end+1] *= 0.5\n",
        "\n",
        "# Create DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'cpu_usage': cpu_usage,\n",
        "    'mem_usage': mem_usage,\n",
        "    'disk_usage': disk_usage,\n",
        "    'net_throughput': net_throughput,\n",
        "    'active_nodes': active_nodes,\n",
        "    'active_pods': active_pods,\n",
        "    'error_rate': error_rate,\n",
        "    'label': labels\n",
        "})\n"
      ],
      "metadata": {
        "id": "YY-1xdxlLS-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 3: Preprocess Data\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "feature_cols = ['cpu_usage', 'mem_usage', 'disk_usage', 'net_throughput', 'error_rate']  # Removed less useful features\n",
        "X_features = scaler.fit_transform(data[feature_cols])\n",
        "y_labels = data['label']\n",
        "\n",
        "# Apply SMOTE oversampling to balance classes\n",
        "smote = SMOTE()\n",
        "X_resampled, y_resampled = smote.fit_resample(X_features, y_labels)\n",
        "\n",
        "# Reshape for LSTM input\n",
        "X_resampled = X_resampled.reshape((X_resampled.shape[0], 1, X_resampled.shape[1]))"
      ],
      "metadata": {
        "id": "Bgq7FBkbLW0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 4: Define and Train LSTM Model\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(256, return_sequences=True, input_shape=(1, X_resampled.shape[2])),\n",
        "    LSTM(128, activation='tanh'),\n",
        "    Dropout(0.3),\n",
        "    Dense(7, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_resampled, y_resampled, epochs=50, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0LcuGYhLZkl",
        "outputId": "c3bdef93-225c-4a20-bab7-7d0829bbe026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119/119 - 3s - 27ms/step - accuracy: 0.5619 - loss: 1.3590\n",
            "Epoch 2/50\n",
            "119/119 - 1s - 9ms/step - accuracy: 0.9235 - loss: 0.2139\n",
            "Epoch 3/50\n",
            "119/119 - 1s - 10ms/step - accuracy: 0.9495 - loss: 0.1214\n",
            "Epoch 4/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9556 - loss: 0.1023\n",
            "Epoch 5/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9578 - loss: 0.0954\n",
            "Epoch 6/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9570 - loss: 0.0948\n",
            "Epoch 7/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9566 - loss: 0.0949\n",
            "Epoch 8/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9586 - loss: 0.0909\n",
            "Epoch 9/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9569 - loss: 0.0902\n",
            "Epoch 10/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9624 - loss: 0.0857\n",
            "Epoch 11/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9589 - loss: 0.0910\n",
            "Epoch 12/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9606 - loss: 0.0860\n",
            "Epoch 13/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9636 - loss: 0.0834\n",
            "Epoch 14/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9599 - loss: 0.0855\n",
            "Epoch 15/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9632 - loss: 0.0825\n",
            "Epoch 16/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9636 - loss: 0.0796\n",
            "Epoch 17/50\n",
            "119/119 - 1s - 7ms/step - accuracy: 0.9647 - loss: 0.0745\n",
            "Epoch 18/50\n",
            "119/119 - 1s - 7ms/step - accuracy: 0.9668 - loss: 0.0716\n",
            "Epoch 19/50\n",
            "119/119 - 1s - 8ms/step - accuracy: 0.9684 - loss: 0.0707\n",
            "Epoch 20/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9709 - loss: 0.0633\n",
            "Epoch 21/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9689 - loss: 0.0621\n",
            "Epoch 22/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9729 - loss: 0.0578\n",
            "Epoch 23/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9749 - loss: 0.0539\n",
            "Epoch 24/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9746 - loss: 0.0518\n",
            "Epoch 25/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9754 - loss: 0.0507\n",
            "Epoch 26/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9775 - loss: 0.0471\n",
            "Epoch 27/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9779 - loss: 0.0462\n",
            "Epoch 28/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9769 - loss: 0.0469\n",
            "Epoch 29/50\n",
            "119/119 - 1s - 11ms/step - accuracy: 0.9792 - loss: 0.0470\n",
            "Epoch 30/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9796 - loss: 0.0449\n",
            "Epoch 31/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9803 - loss: 0.0442\n",
            "Epoch 32/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9779 - loss: 0.0447\n",
            "Epoch 33/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9784 - loss: 0.0464\n",
            "Epoch 34/50\n",
            "119/119 - 2s - 13ms/step - accuracy: 0.9813 - loss: 0.0413\n",
            "Epoch 35/50\n",
            "119/119 - 1s - 6ms/step - accuracy: 0.9835 - loss: 0.0382\n",
            "Epoch 36/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9831 - loss: 0.0398\n",
            "Epoch 37/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9840 - loss: 0.0379\n",
            "Epoch 38/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9821 - loss: 0.0394\n",
            "Epoch 39/50\n",
            "119/119 - 1s - 11ms/step - accuracy: 0.9849 - loss: 0.0362\n",
            "Epoch 40/50\n",
            "119/119 - 1s - 11ms/step - accuracy: 0.9873 - loss: 0.0341\n",
            "Epoch 41/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9856 - loss: 0.0353\n",
            "Epoch 42/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9872 - loss: 0.0341\n",
            "Epoch 43/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9865 - loss: 0.0331\n",
            "Epoch 44/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9874 - loss: 0.0316\n",
            "Epoch 45/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9893 - loss: 0.0289\n",
            "Epoch 46/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9890 - loss: 0.0298\n",
            "Epoch 47/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9894 - loss: 0.0294\n",
            "Epoch 48/50\n",
            "119/119 - 1s - 5ms/step - accuracy: 0.9882 - loss: 0.0295\n",
            "Epoch 49/50\n",
            "119/119 - 1s - 7ms/step - accuracy: 0.9902 - loss: 0.0259\n",
            "Epoch 50/50\n",
            "119/119 - 1s - 11ms/step - accuracy: 0.9898 - loss: 0.0272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 5: Evaluate Model\n",
        "\n",
        "y_pred_probs = model.predict(X_resampled)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "print(\"Classification Report:\\n\", classification_report(y_resampled, y_pred, digits=4))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_resampled, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcm3kJhYLbyg",
        "outputId": "d28524db-a43a-484e-d876-e918eab7e536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9751    0.9806    0.9778      1080\n",
            "           1     1.0000    1.0000    1.0000      1080\n",
            "           2     0.9804    0.9750    0.9777      1080\n",
            "           3     1.0000    1.0000    1.0000      1080\n",
            "           4     1.0000    1.0000    1.0000      1080\n",
            "           5     1.0000    1.0000    1.0000      1080\n",
            "           6     1.0000    1.0000    1.0000      1080\n",
            "\n",
            "    accuracy                         0.9937      7560\n",
            "   macro avg     0.9937    0.9937    0.9937      7560\n",
            "weighted avg     0.9937    0.9937    0.9937      7560\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1059    0   21    0    0    0    0]\n",
            " [   0 1080    0    0    0    0    0]\n",
            " [  27    0 1053    0    0    0    0]\n",
            " [   0    0    0 1080    0    0    0]\n",
            " [   0    0    0    0 1080    0    0]\n",
            " [   0    0    0    0    0 1080    0]\n",
            " [   0    0    0    0    0    0 1080]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/Model Saves/Phase_1_99.3.h5')\n",
        "model.save('/content/Model Saves/Phase_1_99.3.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo8K44xeJPtC",
        "outputId": "9e88bd41-0ce6-46b0-ee4e-1f70807d9807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Testing"
      ],
      "metadata": {
        "id": "GKlOZ5LrQ_hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/elastic_february2022_data.csv\"  # Adjust if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display dataset summary\n",
        "print(\"Dataset Overview:\")\n",
        "print(df.head())  # Show first few rows\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())  # Show column names and types\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-k3Gv06RBWh",
        "outputId": "138b7a32-7fce-426b-facb-67994b91f41d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Overview:\n",
            "                           _source_flow_id  _source_flow_final  \\\n",
            "0       EAD/////AP////////8AAAGsEAILrBACDA               False   \n",
            "1       EAD/////AP////////8AAAGsEAIKrBACDA               False   \n",
            "2  EAT/////AP//////CP8AAAHAqFSDwKj3AAEIbQI               False   \n",
            "3  EAT/////AP//////CP8AAAHAqFSPwKj3D8CeVCQ               False   \n",
            "4  EAT/////AP//////CP8AAAEKapNUwKj3DvAjvpo               False   \n",
            "\n",
            "  _source_source_ip _source_destination_ip  _source_network_bytes  \\\n",
            "0    240.16.203.232         240.16.203.236               72096053   \n",
            "1    240.16.203.236         240.16.203.233                 913734   \n",
            "2    190.215.171.30           190.215.9.27               30684984   \n",
            "3    190.215.171.17           190.215.9.16                 220136   \n",
            "4      190.215.9.17         53.181.234.140                  73242   \n",
            "\n",
            "  _source_network_transport        _source_@timestamp  _source_event_duration  \\\n",
            "0                       NaN  2022-02-25T12:20:00.007Z             41753051589   \n",
            "1                       NaN  2022-02-25T12:20:00.007Z             35268442180   \n",
            "2                       tcp  2022-02-25T12:20:00.007Z             41662926223   \n",
            "3                       tcp  2022-02-25T12:20:00.007Z             41154340691   \n",
            "4                       tcp  2022-02-25T12:20:00.007Z             41259502779   \n",
            "\n",
            "   _source_destination_port  _source_source_port   label  \n",
            "0                       NaN                  NaN  benign  \n",
            "1                       NaN                  NaN  benign  \n",
            "2                     621.0               2049.0  benign  \n",
            "3                    9300.0              40640.0  benign  \n",
            "4                    9200.0              39614.0  benign  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398414 entries, 0 to 398413\n",
            "Data columns (total 11 columns):\n",
            " #   Column                     Non-Null Count   Dtype  \n",
            "---  ------                     --------------   -----  \n",
            " 0   _source_flow_id            398414 non-null  object \n",
            " 1   _source_flow_final         398414 non-null  bool   \n",
            " 2   _source_source_ip          398414 non-null  object \n",
            " 3   _source_destination_ip     398414 non-null  object \n",
            " 4   _source_network_bytes      398414 non-null  int64  \n",
            " 5   _source_network_transport  396080 non-null  object \n",
            " 6   _source_@timestamp         398414 non-null  object \n",
            " 7   _source_event_duration     398414 non-null  int64  \n",
            " 8   _source_destination_port   395857 non-null  float64\n",
            " 9   _source_source_port        395857 non-null  float64\n",
            " 10  label                      398414 non-null  object \n",
            "dtypes: bool(1), float64(2), int64(2), object(6)\n",
            "memory usage: 30.8+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ngBNVwKuRFxH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNxWws3idCWsUkeELX4JCzP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}